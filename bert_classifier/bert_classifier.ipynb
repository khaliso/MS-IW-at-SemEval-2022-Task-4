{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's install and import some stuff first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "from urllib import request\n",
    "import tensorflow\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Don't Patronize Me Module and Scorer (we only have to do this once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'module_url = f\"https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\"\\nmodule_name = module_url.split(\\'/\\')[-1]\\nprint(f\\'Fetching {module_url}\\')\\n#with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\\nwith request.urlopen(module_url) as f, open(module_name,\\'w\\') as outf:\\n  a = f.read()\\n  outf.write(a.decode(\\'utf-8\\'))'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''module_url = f\"https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/dont_patronize_me.py\"\n",
    "module_name = module_url.split('/')[-1]\n",
    "print(f'Fetching {module_url}')\n",
    "#with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\n",
    "with request.urlopen(module_url) as f, open(module_name,'w') as outf:\n",
    "  a = f.read()\n",
    "  outf.write(a.decode('utf-8'))\n",
    "  \n",
    "module_url = f\"https://raw.githubusercontent.com/Perez-AlmendrosC/dontpatronizeme/master/semeval-2022/evaluation.py\"\n",
    "module_name = module_url.split('/')[-1]\n",
    "print(f'Fetching {module_url}')\n",
    "#with open(\"file_1.txt\") as f1, open(\"file_2.txt\") as f2\n",
    "with request.urlopen(module_url) as f, open(module_name,'w') as outf:\n",
    "  a = f.read()\n",
    "  outf.write(a.decode('utf-8'))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read in the dataset. Since right now, we only want to be able to classify our synthetic data, we will balance our dataset by downsampling the nontoxic data. We store train and test data in csv-files for later use (esp. for comparibility). Again, we only have to do this once. Once we have saved the data, we can skip this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from dont_patronize_me import DontPatronizeMe\n",
    "\n",
    "dpm = DontPatronizeMe('.', 'dontpatronizeme_pcl.tsv')\n",
    "dpm.load_task1()\n",
    "dpm.train_task1_df.head()\n",
    "\n",
    "df_nontoxic = dpm.train_task1_df[dpm.train_task1_df[\"label\"] == 0]\n",
    "df_toxic = dpm.train_task1_df[dpm.train_task1_df[\"label\"] == 1]\n",
    "\n",
    "df_nontoxic_downsampled = df_nontoxic.sample(df_toxic.shape[0])\n",
    "\n",
    "dpm_balanced = pd.concat([df_toxic, df_nontoxic_downsampled])\n",
    "\n",
    "X = dpm_balanced[\"text\"].values.tolist()\n",
    "y = dpm_balanced[\"label\"].values.tolist()\n",
    "\n",
    "# Let's split the dataset into train and test data. We will store both for later use.\n",
    "train_text, test_text, train_labels, test_labels = train_test_split(X, y, random_state=42, test_size=.1, stratify=y)\n",
    "\n",
    "train_data = pd.DataFrame({\"text\": train_text, \"label\": train_labels})\n",
    "test_data = pd.DataFrame({\"text\": test_text, \"label\": test_labels})\n",
    "\n",
    "test_data.to_csv(\"test_data_downsampled.csv\")\n",
    "train_data.to_csv(\"train_data_downsampled.csv\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have already created the csv-files, we can read them in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data_downsampled.csv\")\n",
    "test_data = pd.read_csv(\"test_data_downsampled.csv\")\n",
    "\n",
    "train_text = train_data[\"text\"].values.tolist()\n",
    "train_labels = train_data[\"labels\"].values.tolist()\n",
    "\n",
    "test_text = test_data[\"text\"].values.tolist()\n",
    "test_labels = test_data[\"labels\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training set further into training and validation data. We will use this data for finetuning\n",
    "train_text, val_text, train_labels, val_labels = train_test_split(train_text, train_labels, random_state=42,\n",
    "                                                                  test_size=.1, stratify=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing our data\n",
    "encoded_train = tokenizer(train_text, truncation=True, padding=True)\n",
    "encoded_val = tokenizer(val_text, truncation=True, padding=True)\n",
    "encoded_test = tokenizer(test_text, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function for mapping encoded data to labels\n",
    "class dpm_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dpm_dataset(encoded_train, train_labels)\n",
    "val_set = dpm_dataset(encoded_val, val_labels)\n",
    "test_set = dpm_dataset(encoded_test, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have trained and saved the model before, we can load it here (2nd line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', num_labels=2)\n",
    "#model = AutoModelForSequenceClassification.from_pretrained('semeval_task4/model_downsampled', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining metrics our trainer uses in evaluation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fine-tune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1608\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 603\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='603' max='603' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [603/603 03:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.432008</td>\n",
       "      <td>0.810056</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.744444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.490392</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.862944</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.390900</td>\n",
       "      <td>0.643342</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.839378</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 179\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 179\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Configuration saved in test_trainer/checkpoint-500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 179\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=603, training_loss=0.3472985968265565, metrics={'train_runtime': 214.4514, 'train_samples_per_second': 22.495, 'train_steps_per_second': 2.812, 'total_flos': 1269247731056640.0, 'train_loss': 0.3472985968265565, 'epoch': 3.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check how our model performs on our test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redefining compute_metrics function to fit trainer.predict returns\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "    }\n",
    "\n",
    "y_pred = trainer.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8492462311557789,\n",
       " 'f1': 0.8543689320388348,\n",
       " 'precision': 0.822429906542056,\n",
       " 'recall': 0.8888888888888888}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fa73459acf8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAAEGCAYAAADmLRl+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAYg0lEQVR4nO3de7hWZZ3/8feHjcpR5CwHDUKU+DGKio5pFqXjoSypX3bpjEkzmKXTwcNYTDXT6NQVM/1+dvjVNGGWdDLJZODXpIRMlhYeEFBBBDwiugVRUZTTZu/v/LEW0wNt97MWPM9+1tp8Xte1rv2s+1n7Xt8N1/W97vte97pvRQRmZmXWrdEBmJntKycyMys9JzIzKz0nMjMrPScyMyu97o0OoNIhA5ri0JGFCsmqaF7dv9EhWA5bW15hR+tW7UsdZ76zd7z4Umumax94aPv8iDhrX+6XRaGyxqEju3P9vJGNDsNy+PIZ/7vRIVgOi9b+cJ/rePGlVu6bf3ima5uGrRm0zzfMoFCJzMyKL4A22hodxm6cyMwslyBoiWxdy87iRGZmublFZmalFgStBXu10YnMzHJrw4nMzEosgFYnMjMrO7fIzKzUAmjxGJmZlVkQ7lqaWckFtBYrjzmRmVk+ycz+YnEiM7OcRCv79N55zTmRmVkuyWC/E5mZlVgyj8yJzMxKrs0tMjMrM7fIzKz0AtFasFXyncjMLDd3Lc2s1AKxI5pqUpekK4CLSXqsDwN/DfQCbgZGAU8BH4qIlzuqp1jtQzMrvGRCbLdMR0ckjQA+BUyKiAlAE3A+MB1YGBFjgYXpeYecyMwst9Z0Umy1I4PuQE9J3UlaYs8B5wKz0u9nAVOyVGJmllmEaI3MbaBBkhZXnM+MiJlJPfGspP8DrAW2Ar+OiF9LGhoRzek1zZKGVLuJE5mZ5daWffrFxoiY1N4XkvqTtL5GA5uAn0u6cG/icSIzs1ySwf6apI7TgScj4gUASbcCJwPrJQ1LW2PDgA3VKvIYmZnlUqvBfpIu5UmSekkScBqwEpgHTE2vmQrMrVaRW2RmlltrDeaRRcS9km4BlgA7gaXATKAPMFvSNJJkd161upzIzCyXWs7sj4gvAl/co3g7SessMycyM8utLftTy07hRGZmuSQvjTuRmVmJBaKlRq8o1YoTmZnlEkGeCbGdwonMzHJSngmxncKJzMxyCdwiM7MuwIP9ZlZqgbywopmVW7IdXLFSR7GiMbMS8Aa9ZlZygWf2m1kX4BaZmZVahNwiM7NySwb7/YqSmZVarjX7O4UTmZnlkgz2e4zMzErOM/vNrNQ8s9/MuoQMG4t0qmJFY2aFFwEtbd0yHR2RdJSkZRXHq5IulzRA0gJJa9Kf/avF5ERmZrkkXctumY4O64lYFRETI2IicDywBZgDTAcWRsRYYGF63iEnMjPLrTV937LakcNpwOMR8TTJ7uOz0vJZwJRqv+wxshq754YhLJ09EARDjtzKuV99mtUL+/Hbbwzjhcd6cPGcVQw/ekujw7TU5Z9dwoknP8+mlw/iso8kO5CNHvMKn7hqGT17tbK+uSf/+s+T2LrlgAZHWhw5p18MkrS44nxmRMxs57rzgZvSz0Mjohkg3W18SLWb1LVFJuksSaskPSapavOw7F59/gDumzWYi+c+yqW3ryTaxPL/35/BR27jvO88wZtOfK3RIdoe7rj9cP7h6pN3K/v0Z5byg+/+Ly77yLv4w13D+eAFaxoUXVHl6lpujIhJFcefJDFJBwLvA36+txHVLZFJagK+DZwNjAcukDS+XvcrirZWsXNbN9p2QsvWbvQd2sLgI7Yx6M3bGx2atWP5g4PY/Orura2Rh7/G8gcHArB08WBOeUdzI0IrtLZ03f5qR0ZnA0siYn16vl7SMID054ZqFdSzRXYi8FhEPBERO4CfkfR9u6yDD23hrRev5+tvm8B1J/0ZB/VtZcypmxsdluX01JMHc9Lbngfg1MnPMWjI1gZHVCzJU8umTEdGF/DHbiXAPGBq+nkqMLdaBfVMZCOAZyrO16Vlu5F0iaTFkhZverGtjuHU39ZXmlh1xyF86rcruGLRw7Rs7cZD/zGg0WFZTl+fcSznvP8JvnH9b+jZayc7W4o1+bPRdk2IzXJUI6kX8BfArRXFM4C/kLQm/W5GtXrqOdjf3l8Rf1KQ9JlnAow7+qA/+b5Mnvx9Xw4ZuZ3eA3cCMO7MTax7oDdHT3mpwZFZHuvW9uULV50CwIiRr3HCW59vcETFU6vt4CJiCzBwj7IXSZ5iZlbPFtk64LCK85HAc3W8X8MdPHwHzy7rTctWEQFP/qEvg47Y1uiwLKd+hyTjmVJw/kWr+NXc0Q2OqFh2PbWsRYusVurZIrsfGCtpNPAsyePVv6zj/Rpu5MQtvOWsTcx871vo1j04dPwWjjt/I4/O78dt1xzGlpe6c9O0MQwdv5ULZz3W6HAN+Mw/3s/Rx27k4H47+OEtt/PjH4yjZ89Wznn/EwD8/nfDWfCrwxscZfHsNwsrRsROSZ8A5gNNwPcjYkW97lcUk69oZvIVuz/lGnfmK4w785UGRWQd+ddrT2i3fO4tYzo5kvKIEDv3l0QGEBG/An5Vz3uYWefz6hdmVmpeWNHMugQnMjMrNS+saGZdQq3mkdWKE5mZ5RIBO6ssmtjZnMjMLDd3Lc2s1DxGZmZdQjiRmVnZebDfzEotwmNkZlZ6otVPLc2s7DxGZmal5nctzaz8IhknKxInMjPLrWhPLYs1YmdmhRfpYH+WoxpJh0i6RdKjklZKequkAZIWSFqT/uxfrR4nMjPLLSLbkcE3gNsjYhxwDLASmA4sjIixwML0vENOZGaWW4QyHR2RdDDwduCGpM7YERGbSPa/nZVeNguYUi0eJzIzyyVpbWVOZIN27VubHpdUVPVm4AXgB5KWSvqepN7A0IhoTu4VzcCQajF5sN/Mcssx/WJjREx6g++6A8cBn4yIeyV9gwzdyPa4RWZmudVojGwdsC4i7k3PbyFJbOslDQNIf26oVpETmZnlEoi2tm6Zjg7riXgeeEbSUWnRacAjwDxgalo2FZhbLSZ3Lc0stxrOh/0k8BNJBwJPAH9N0sCaLWkasBY4r1olTmRmlk/U7l3LiFgGtDeGdlqeepzIzCy/sryilM7xeEMR8WrtwzGzMijT6hcrSPJuZcS7zgM4vI5xmVlBBdDWVpJEFhGHdWYgZlYSARSsRZZp+oWk8yV9Lv08UtLx9Q3LzIqshu9a1kTVRCbpW8A7gQ+nRVuAf69nUGZWcJHx6CRZnlqeHBHHSVoKEBEvpXM+zGy/VP2F8M6WJZG1SOpGml8lDQTa6hqVmRVbWaZfVPg28AtgsKRrgA8B19Q1KjMrroAoy1PLXSLih5IeAE5Pi86LiOX1DcvMiq1kiSzVBLSQNCj9ornZ/q5gXcssTy0/D9wEDAdGAj+V9Pf1DszMCqyETy0vBI6PiC0Akr4MPAB8pZ6BmVlBFXBCbJZE9vQe13UnWW7DzPZTpdnXUtLXSHLvFmCFpPnp+RnA3Z0TnpkVUomeWu56MrkC+M+K8nvqF46ZlYHK0iKLiBs6MxAzK4lOHsjPouoYmaQxwJeB8UCPXeURcWQd4zKzwlLhBvuzzAm7EfgByQy4s4HZwM/qGJOZFV3Bpl9kSWS9ImI+QEQ8HhFfIFkNw8z2V20Zj06SZfrFdkkCHpf0ceBZMuz8a2ZdVA3nkUl6CtgMtAI7I2KSpAHAzcAo4CngQxHxckf1ZGmRXQH0AT4FnAJ8FPibvQ3czMpPke3I6J0RMbFiR/LpwMKIGAssJMPu41leGt+1C/Bm/ri4opntz+o7/nUuMDn9PAu4E/hsR7/Q0YTYOXQQbkR8IHd4Zra/GSRpccX5zIiYWXEewK8lBfDd9LuhEdEMEBHNkqoOZXXUIvvW3kS9L557uDfXvvm4zr6t7YP5z81pdAiWw4lnbqpJPTm6jRsruoztOSUinkuT1QJJj+5NPB1NiF24NxWaWRcX1OwVpYh4Lv25Ie0FngislzQsbY0NAzZUq8dri5lZfjWYRyapt6S+uz6TvMe9HJgHTE0vmwrMrRZO1oUVzcz+R43etRwKzElmd9Ed+GlE3C7pfmC2pGnAWuC8ahVlTmSSDoqI7XsZsJl1JTVIZBHxBHBMO+UvAqflqSvLCrEnSnoYWJOeHyPp/+W5iZl1MSV8RembwDnAiwAR8SB+Rclsv5V1MmxnLvWTpWvZLSKeTvuxu7TWKR4zK4MSLay4yzOSTgRCUhPwSWB1fcMysyIrzcKKFS4l6V4eDqwH7kjLzGx/VbZEFhEbgPM7IRYzK4NOHv/KIssKsdfTTv6NiEvqEpGZFV/ZEhlJV3KXHsD7gWfqE46ZlYE6cdHELLJ0LW+uPJf0I2BB3SIyM8tpb15RGg28qdaBmFmJlK1rKell/hh2N+AlMqzYaGZdVNkG+9O1+o8hWacfoC2iaJulm1mnK1gW6PAVpTRpzYmI1vQoWPhm1hAlfNfyPklettXMgGSDW7VlOzpLR2v2d4+IncDbgI9Kehx4neTviIhwcjPbH5VsjOw+4DhgSifFYmZlUaJEJkh2F++kWMysLEqUyAZLuvKNvoyI6+oQj5mVQJm6lk0kO4wXa+EhM2u8EiWy5oi4ttMiMbNyiNo+kUzXOVwMPBsR50gaANwMjAKeAj4UES93VEdH0y/cEjOz9tV2HtmngZUV59OBhRExFlhIhjeJOkpkuXYxMbP9R63W7Jc0EngP8L2K4nOBWennWWSYOdHRTuMvVQ/DzPZL2VtbgyQtrjifGREzK86/DnwG6FtRNjQimgHS3caHVLuJN+g1s3zydRs3RsSk9r6QdA6wISIekDR5X0JyIjOzXETNpl+cArxP0rtJFm09WNKPgfWShqWtsWHAhmoVZXnX0sxsN7UYI4uIv4+IkREximRfkP+KiAuBecDU9LKpwNxq8bhFZmb51Xce2QxgtqRpwFrgvGq/4ERmZvnVOJFFxJ3AnennF8k5a8KJzMzyKdnqF2Zm7XMiM7OyK912cGZme3LX0szKrZPX48/CiczM8nMiM7Myq+HM/ppxIjOz3NRWrEzmRGZm+XiMzMy6Anctzaz8nMjMrOzcIjOz8nMiM7NSq/EuSrXgRGZmuXgemZl1DVGsTOZEZma5uUXWxV153Vr+/PTNbNrYnY+96ygATj1nEx++6nkOG7udT717LGse6tXgKK3SrTMHc9tPByDB6HHbuOpra3nmsR58c/pIdmzrRlP34BNfWce4Y7c0OtRiKOCE2LptPiLp+5I2SFper3sU0a9vHsDn/2r0bmVPPdqDay8excP39G5QVPZGNjYfwH/cMIhv3baamb9ZRWsb3Dm3P9/70jAuvPJ5vnPHKi66upkbvjS80aEWitqyHZ2lnrso3QicVcf6C2n5vX3Y/PLuDd1nHuvBusd7NCgiq6Z1p9i+rRutO2H71m4MHNqCBK9vbgLg9VebGDC0pcFRFkstEpmkHpLuk/SgpBWSrknLB0haIGlN+rN/tXjq1rWMiN9JGlWv+s1qYdCwFj546QY+fMJ4DuoRHPeOVzl+8mYGj9jB5y4Yw/XXDicCvjZvTaNDLY6gVoP924F3RcRrkg4A7pZ0G/ABYGFEzJA0HZgOfLajihq+r6WkSyQtlrS4he2NDsf2M5s3NbFofj9m3fsIP126nG1bmlj4i/78ctYgPnbNs/zkgUf42D89x3VXHt7oUAulRvtaRkS8lp4ekB4BnAvMSstnAVOqxdPwRBYRMyNiUkRMOoCDGh2O7WeW3tWHQw/bwSEDW+l+AJzy7k08srg3C34+gLe9+xUA3v7eTaxe5gc0u4mMBwza1VBJj0sqq5HUJGkZyW7iCyLiXmBoRDQDpD+HVAvHTy1tvzZkRAsrl/Ri2xZxUM9g2d19OfLoLQwc2sJDi/pwzMmvsezuPgwf7d7CLjknxG6MiElv9GVEtAITJR0CzJE0YW9iciKrsen/9jRHv/U1+g3YyY8XP8KP/u9QNr/cncu+9Cz9Bu7kn3/0JI+v6MHn/3JMo0M1YNxxWzj1Pa/wt2ceRVP34IgJWzn7whcZM2Er3/nHEbS2igMPauPyrz7T6FCLI6LmCytGxCZJd5I8IFwvaVhENEsaRtJa61DdEpmkm4DJJE3LdcAXI+KGet2vKGZc9qZ2y/9we79OjsSyuujq57no6ud3K5vw56/z7fmrGxRRCdQgj0kaDLSkSawncDrwL8A8YCowI/05t1pd9XxqeUG96jazxqrRzP5hwCxJTSTj9bMj4peSFgGzJU0D1gLnVavIXUszyyeAGnQtI+Ih4Nh2yl8ETstTlxOZmeVXsFeUnMjMLDe/NG5mpeft4Mys3Aq4+oUTmZnlkkyILVYmcyIzs/y8Zr+ZlZ1bZGZWbh4jM7Pyq/27lvvKiczM8nPX0sxKzRv0mlmX4BaZmZVesfKYE5mZ5ae2YvUtncjMLJ/AE2LNrNxEeEKsmXUBTmRmVnpOZGZWagUcI2v4Br1mVj5qa8t0dFiHdJik30haKWmFpE+n5QMkLZC0Jv3Zv1o8TmRmllMkXcssR8d2AldFxFuAk4C/lTQemA4sjIixwML0vENOZGaWT1CTRBYRzRGxJP28GVgJjADOBWall80CplQLyWNkZpZf9jGyQZIWV5zPjIiZe14kaRTJ1nD3AkMjohmSZCdpSLWbOJGZWW455pFtjIhJHdYl9QF+AVweEa9Kyh2Pu5Zmll9txsiQdABJEvtJRNyaFq+XNCz9fhiwoVo9TmRmlk8EtLZlOzqgpOl1A7AyIq6r+GoeMDX9PBWYWy0kdy3NLL/aTIg9Bfgw8LCkZWnZ54AZwGxJ04C1wHnVKnIiM7P8apDIIuJukt3l2nNanrqcyMwsnwC8Zr+ZlVtAFOsdJScyM8snqDqQ39mcyMwsP69+YWal50RmZuWWbbJrZ3IiM7N8AvDmI2ZWem6RmVm5hZ9amlnJBYTnkZlZ6Xlmv5mVnsfIzKzUIvzU0sy6ALfIzKzcgmhtbXQQu3EiM7N8vIyPmXUJnn5hZmUWQLhFZmalFl5Y0cy6gKIN9isK9BhV0gvA042Oow4GARsbHYTl0lX/z94UEYP3pQJJt5P8+2SxMSLO2pf7ZVGoRNZVSVpcbbdlKxb/n5WLN+g1s9JzIjOz0nMi6xwzGx2A5eb/sxLxGJmZlZ5bZGZWek5kZlZ6TmR1JOksSaskPSZpeqPjseokfV/SBknLGx2LZedEVieSmoBvA2cD44ELJI1vbFSWwY1A3SdwWm05kdXPicBjEfFEROwAfgac2+CYrIqI+B3wUqPjsHycyOpnBPBMxfm6tMzMasyJrH7UTpnnupjVgRNZ/awDDqs4Hwk816BYzLo0J7L6uR8YK2m0pAOB84F5DY7JrEtyIquTiNgJfAKYD6wEZkfEisZGZdVIuglYBBwlaZ2kaY2OyarzK0pmVnpukZlZ6TmRmVnpOZGZWek5kZlZ6TmRmVnpOZGViKRWScskLZf0c0m99qGuyZJ+mX5+X0erc0g6RNJle3GPf5L0d1nL97jmRkkfzHGvUV6xYv/lRFYuWyNiYkRMAHYAH6/8Uonc/6cRMS8iZnRwySFA7kRm1lmcyMrrLuCItCWyUtK/AUuAwySdIWmRpCVpy60P/M/6aI9Kuhv4wK6KJH1E0rfSz0MlzZH0YHqcDMwAxqStwa+m110t6X5JD0m6pqKuz6drsN0BHFXtj5D00bSeByX9Yo9W5umS7pK0WtI56fVNkr5ace+P7es/pJWfE1kJSepOss7Zw2nRUcAPI+JY4HXgC8DpEXEcsBi4UlIP4HrgvcCpwKFvUP03gd9GxDHAccAKYDrweNoavFrSGcBYkqWKJgLHS3q7pONJXsU6liRRnpDhz7k1Ik5I77cSqJxJPwp4B/Ae4N/Tv2Ea8EpEnJDW/1FJozPcx7qw7o0OwHLpKWlZ+vku4AZgOPB0RNyTlp9EspDj7yUBHEjyys044MmIWAMg6cfAJe3c413ARQAR0Qq8Iqn/HteckR5L0/M+JImtLzAnIrak98jybukESV8i6b72IXmla5fZEdEGrJH0RPo3nAEcXTF+1i+99+oM97IuyomsXLZGxMTKgjRZvV5ZBCyIiAv2uG4itVtGSMBXIuK7e9zj8r24x43AlIh4UNJHgMkV3+1ZV6T3/mREVCY8JI3KeV/rQty17HruAU6RdASApF6SjgQeBUZLGpNed8Eb/P5C4NL0d5skHQxsJmlt7TIf+JuKsbcRkoYAvwPeL6mnpL4k3dhq+gLNkg4A/mqP786T1C2N+c3AqvTel6bXI+lISb0z3Me6MLfIupiIeCFt2dwk6aC0+AsRsVrSJcB/StoI3A1MaKeKTwMz01UfWoFLI2KRpN+n0xtuS8fJ3gIsSluErwEXRsQSSTcDy4CnSbq/1fwDcG96/cPsnjBXAb8FhgIfj4htkr5HMna2RMnNXwCmZPvXsa7Kq1+YWem5a2lmpedEZmal50RmZqXnRGZmpedEZmal50RmZqXnRGZmpfffhWPHpA6jWG8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_pred.label_ids, y_pred.predictions.argmax(-1))\n",
    "ConfusionMatrixDisplay.from_predictions(y_pred.label_ids, y_pred.predictions.argmax(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking pretty good. We can save the model here for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to semeval_task4/model_downsampled\n",
      "Configuration saved in semeval_task4/model_downsampled/config.json\n",
      "Model weights saved in semeval_task4/model_downsampled/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#trainer.save_model('semeval_task4/model_downsampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels2file(p, outf_path):\n",
    "    with open(outf_path,'w') as outf:\n",
    "        for pi in p:\n",
    "            outf.write(','.join([str(k) for k in pi])+'\\n')\n",
    "            \n",
    "!mkdir ref res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
