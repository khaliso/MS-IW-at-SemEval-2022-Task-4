<<<<<<< Updated upstream
# MS@IW at SemEval-2022 Task 4: Patronising and CondescendingLanguage Detection with Synthetically Generated Data
Our approach to SemEval_2022
=======
# MS@IW at SemEval-2022 Task 4: Patronising and Condescending Language Detection with Synthetically Generated Data
We leverage the generative power of state of the art generative pretrained transformer models to increase training set size and remedy class imbalance issues. Our best submitted system is trained on a synthetically enhanced dataset with 10.3 times as many positive samples as the original dataset and reaches an F1 score of 50.62%, which is 10 percentage points higher than our initial system trained on an undersampled version of the original dataset. We explore possible reasons for the comparably low score in the overall task ranking and report on experiments conducted during the post-evaluation phase.
>>>>>>> Stashed changes
